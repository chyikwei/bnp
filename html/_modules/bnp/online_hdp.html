

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>bnp.online_hdp &mdash; sklearn-template 0.1.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> sklearn-template
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">General examples</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">sklearn-template</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>bnp.online_hdp</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for bnp.online_hdp</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Online HDP with variational inference</span>

<span class="sd">This implementation is modified from Chong Wang&#39;s online-hdp code</span>
<span class="sd">(https://github.com/blei-lab/online-hdp)</span>

<span class="sd">Also, some code are from scikit-learn&#39;s online_lda implementation</span>
<span class="sd">and the code structure is the same.</span>
<span class="sd">(https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/decomposition/online_lda.py)</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Author: Chyi-Kwei Yau</span>
<span class="c1"># Original implementation: Chong Wang</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="k">import</span> <span class="n">gammaln</span><span class="p">,</span> <span class="n">psi</span>

<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="k">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="k">import</span> <span class="p">(</span><span class="n">check_random_state</span><span class="p">,</span> <span class="n">check_array</span><span class="p">,</span>
                           <span class="n">gen_batches</span><span class="p">,</span> <span class="n">gen_even_slices</span><span class="p">,</span> <span class="n">_get_n_jobs</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="k">import</span> <span class="n">check_non_negative</span>
<span class="kn">from</span> <span class="nn">sklearn.exceptions</span> <span class="k">import</span> <span class="n">NotFittedError</span>
<span class="kn">from</span> <span class="nn">sklearn.externals.joblib</span> <span class="k">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="kn">from</span> <span class="nn">sklearn.externals.six.moves</span> <span class="k">import</span> <span class="n">xrange</span>

<span class="kn">from</span> <span class="nn">.utils</span> <span class="k">import</span> <span class="p">(</span><span class="n">log_dirichlet_expectation</span><span class="p">,</span>
                    <span class="n">log_stick_expectation</span><span class="p">,</span>
                    <span class="n">stick_expectation</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">.utils.extmath</span> <span class="k">import</span> <span class="p">(</span><span class="n">row_log_normalize_exp</span><span class="p">,</span> <span class="n">mean_change_2d</span><span class="p">,</span>
                            <span class="n">beta_param_update</span><span class="p">)</span>

<span class="n">EPS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>


<span class="k">def</span> <span class="nf">_local_likelihood_bound</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">elog_beta_d_weighted</span><span class="p">,</span> <span class="n">elog_stick</span><span class="p">,</span>
                            <span class="n">gamma_d</span><span class="p">,</span> <span class="n">elog_local_stick</span><span class="p">,</span> <span class="n">log_phi_d</span><span class="p">,</span>
                            <span class="n">phi_d</span><span class="p">,</span> <span class="n">log_zeta_d</span><span class="p">,</span> <span class="n">zeta_d</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;local Log likelihood for 1 record</span>

<span class="sd">    This is calulated through variational bound.</span>
<span class="sd">    log(p(w|v_stick, beta)) will be greater than</span>
<span class="sd">    the sum of:</span>
<span class="sd">    (1) E[log(p(w|pi_d, c_d, z_d, beta))]</span>
<span class="sd">    (2) E[log(p(z_d|pi_d)) - log(q(z_d|phi_d))]</span>
<span class="sd">    (3) E[log(p(pi_d|alpha)) - log(q(pi_d|gamma))]</span>
<span class="sd">    (4) E[log(p(c_d|v_stick) - log(q(c_d|zeta_d))]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1"># (1) `w_d` is mutlinomial distribution</span>
    <span class="n">likelihood</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">phi_d</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">zeta_d</span><span class="p">,</span> <span class="n">elog_beta_d_weighted</span><span class="p">))</span>

    <span class="c1"># (2) `z_d` is mutlinomial distribution</span>
    <span class="n">likelihood</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">elog_local_stick</span> <span class="o">-</span> <span class="n">log_phi_d</span><span class="p">)</span> <span class="o">*</span> <span class="n">phi_d</span><span class="p">)</span>

    <span class="c1"># (3) `pi_d` is Beta distribution</span>
    <span class="n">likelihood</span> <span class="o">+=</span> <span class="p">(</span><span class="n">gamma_d</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">alpha</span><span class="p">))</span>
    <span class="n">gamma_d_col_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gamma_d</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">dig_sum</span> <span class="o">=</span> <span class="n">psi</span><span class="p">(</span><span class="n">gamma_d_col_sum</span><span class="p">)</span>
    <span class="n">likelihood</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">alpha</span><span class="p">])[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">-</span> <span class="n">gamma_d</span><span class="p">)</span> <span class="o">*</span>
                         <span class="p">(</span><span class="n">psi</span><span class="p">(</span><span class="n">gamma_d</span><span class="p">)</span> <span class="o">-</span> <span class="n">dig_sum</span><span class="p">))</span>
    <span class="n">likelihood</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gammaln</span><span class="p">(</span><span class="n">gamma_d</span><span class="p">))</span>
    <span class="n">likelihood</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gammaln</span><span class="p">(</span><span class="n">gamma_d_col_sum</span><span class="p">))</span>

    <span class="c1"># (4) `c_d` is mutlinomial distribution</span>
    <span class="n">likelihood</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">elog_stick</span> <span class="o">-</span> <span class="n">log_zeta_d</span><span class="p">)</span> <span class="o">*</span> <span class="n">zeta_d</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">likelihood</span>


<span class="k">def</span> <span class="nf">_update_var_local_params</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">elog_beta</span><span class="p">,</span> <span class="n">elog_stick</span><span class="p">,</span> <span class="n">n_doc_truncate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span>
                             <span class="n">max_iters</span><span class="p">,</span> <span class="n">mean_change_tol</span><span class="p">,</span> <span class="n">cal_sstats</span><span class="p">,</span>
                             <span class="n">cal_doc_distr</span><span class="p">,</span> <span class="n">burn_in_iters</span><span class="p">,</span>
                             <span class="n">check_doc_likelihood</span><span class="p">,</span> <span class="n">cal_likelihood</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Update local variational parameter</span>

<span class="sd">    This is step 3~10 in reference [1]</span>

<span class="sd">    Paramters</span>
<span class="sd">    ---------</span>
<span class="sd">    TODO</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    (doc_topic_distr, suff_stats) :</span>
<span class="sd">        `doc_topic_distr` is unnormalized topic distribution for each document.</span>
<span class="sd">        In the literature, this is `gamma`. we can calculate `E[log(theta)]`</span>
<span class="sd">        from it.</span>
<span class="sd">        `suff_stats` is expected sufficient statistics for the M-step.</span>
<span class="sd">            When `cal_sstats == False`, this will be None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">is_sparse_x</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_topic_truncate</span> <span class="o">=</span> <span class="n">elog_beta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">cal_sstats</span><span class="p">:</span>
        <span class="n">suff_stats</span> <span class="o">=</span> <span class="p">{</span>
            <span class="c1"># ss_lambda, shape = (K, n_features)</span>
            <span class="s1">&#39;lambda&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">elog_beta</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
            <span class="c1"># ss_v_stick, shape = (K,)</span>
            <span class="s1">&#39;v_stick&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">elog_beta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">suff_stats</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">doc_likelihood</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="k">if</span> <span class="n">cal_likelihood</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">cal_doc_distr</span><span class="p">:</span>
        <span class="n">doc_topic_distr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_topic_truncate</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">doc_topic_distr</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">is_sparse_x</span><span class="p">:</span>
        <span class="n">X_data</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">data</span>
        <span class="n">X_indices</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">indices</span>
        <span class="n">X_indptr</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">indptr</span>

    <span class="k">for</span> <span class="n">idx_d</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
        <span class="c1"># get word_id and count in each document</span>
        <span class="k">if</span> <span class="n">is_sparse_x</span><span class="p">:</span>
            <span class="n">ids</span> <span class="o">=</span> <span class="n">X_indices</span><span class="p">[</span><span class="n">X_indptr</span><span class="p">[</span><span class="n">idx_d</span><span class="p">]:</span><span class="n">X_indptr</span><span class="p">[</span><span class="n">idx_d</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span>
            <span class="n">cnts</span> <span class="o">=</span> <span class="n">X_data</span><span class="p">[</span><span class="n">X_indptr</span><span class="p">[</span><span class="n">idx_d</span><span class="p">]:</span><span class="n">X_indptr</span><span class="p">[</span><span class="n">idx_d</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx_d</span><span class="p">,</span> <span class="p">:])[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">cnts</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idx_d</span><span class="p">,</span> <span class="n">ids</span><span class="p">]</span>

        <span class="c1"># check if doc is empty</span>
        <span class="k">if</span> <span class="n">ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="c1"># follow reference [3]</span>
        <span class="c1"># elog_beta_d, shape = (K, N_unique)</span>
        <span class="n">elog_beta_d</span> <span class="o">=</span> <span class="n">elog_beta</span><span class="p">[:,</span> <span class="n">ids</span><span class="p">]</span>
        <span class="n">elog_beta_d_weighted</span> <span class="o">=</span> <span class="n">elog_beta_d</span> <span class="o">*</span> <span class="n">cnts</span>
        <span class="n">phi_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">),</span> <span class="n">n_doc_truncate</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">n_doc_truncate</span><span class="p">)</span>

        <span class="c1"># initialized gamma_d, shape = (2, T-1)</span>
        <span class="n">gamma_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_doc_truncate</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">elog_local_stick</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_doc_truncate</span><span class="p">)</span>

        <span class="n">old_likelihood</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1e100</span>
        <span class="c1"># update variables</span>
        <span class="k">for</span> <span class="n">n_iter</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_iters</span><span class="p">):</span>
            <span class="n">last_phi_d</span> <span class="o">=</span> <span class="n">phi_d</span>

            <span class="k">if</span> <span class="n">n_iter</span> <span class="o">&lt;</span> <span class="n">burn_in_iters</span><span class="p">:</span>
                <span class="n">log_zeta_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">phi_d</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">elog_beta_d_weighted</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
                <span class="n">log_zeta_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">log_zeta_d</span><span class="p">)</span>
                <span class="n">row_log_normalize_exp</span><span class="p">(</span><span class="n">log_zeta_d</span><span class="p">)</span>
                <span class="n">zeta_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_zeta_d</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_zeta_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">phi_d</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">elog_beta_d_weighted</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> \
                    <span class="n">elog_stick</span>
                <span class="n">log_zeta_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">log_zeta_d</span><span class="p">)</span>
                <span class="n">row_log_normalize_exp</span><span class="p">(</span><span class="n">log_zeta_d</span><span class="p">)</span>
                <span class="n">zeta_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_zeta_d</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">n_iter</span> <span class="o">&lt;</span> <span class="n">burn_in_iters</span><span class="p">:</span>
                <span class="n">log_phi_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">zeta_d</span><span class="p">,</span> <span class="n">elog_beta_d</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
                <span class="n">log_phi_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">log_phi_d</span><span class="p">)</span>
                <span class="n">row_log_normalize_exp</span><span class="p">(</span><span class="n">log_phi_d</span><span class="p">)</span>
                <span class="n">phi_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_phi_d</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_phi_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">zeta_d</span><span class="p">,</span> <span class="n">elog_beta_d</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">elog_local_stick</span>
                <span class="n">log_phi_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">log_phi_d</span><span class="p">)</span>
                <span class="n">row_log_normalize_exp</span><span class="p">(</span><span class="n">log_phi_d</span><span class="p">)</span>
                <span class="n">phi_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_phi_d</span><span class="p">)</span>

            <span class="c1"># phi_all, shape = (N, T)</span>
            <span class="n">phi_all</span> <span class="o">=</span> <span class="n">phi_d</span> <span class="o">*</span> <span class="n">cnts</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="c1"># update gamma_d, zeta_d (step 8. in ref [1])</span>
            <span class="n">phi_row_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">phi_all</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">beta_param_update</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">phi_row_sum</span><span class="p">,</span> <span class="n">gamma_d</span><span class="p">)</span>
            <span class="c1"># E[log(pi_{d})], shape = (T,)</span>
            <span class="n">elog_local_stick</span> <span class="o">=</span> <span class="n">log_stick_expectation</span><span class="p">(</span><span class="n">gamma_d</span><span class="p">)</span>

            <span class="c1"># check convergence</span>
            <span class="n">m_change</span> <span class="o">=</span> <span class="n">mean_change_2d</span><span class="p">(</span><span class="n">last_phi_d</span><span class="p">,</span> <span class="n">phi_d</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">check_doc_likelihood</span> <span class="ow">and</span> <span class="n">n_iter</span> <span class="o">&gt;=</span> <span class="n">burn_in_iters</span><span class="p">:</span>
                <span class="n">likelihood</span> <span class="o">=</span> <span class="n">_local_likelihood_bound</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span>
                                                     <span class="n">elog_beta_d_weighted</span><span class="p">,</span>
                                                     <span class="n">elog_stick</span><span class="p">,</span>
                                                     <span class="n">gamma_d</span><span class="p">,</span>
                                                     <span class="n">elog_local_stick</span><span class="p">,</span>
                                                     <span class="n">log_phi_d</span><span class="p">,</span>
                                                     <span class="n">phi_d</span><span class="p">,</span>
                                                     <span class="n">log_zeta_d</span><span class="p">,</span>
                                                     <span class="n">zeta_d</span><span class="p">)</span>

                <span class="n">converge</span> <span class="o">=</span> <span class="p">(</span><span class="n">likelihood</span> <span class="o">-</span> <span class="n">old_likelihood</span><span class="p">)</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">old_likelihood</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">converge</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mf">0.001</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;warning: likelihood decrease: </span><span class="si">%.5f</span><span class="s2"> -&gt; </span><span class="si">%.5f</span><span class="s2">&quot;</span> <span class="o">%</span>
                          <span class="p">(</span><span class="n">old_likelihood</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">))</span>
                <span class="n">old_likelihood</span> <span class="o">=</span> <span class="n">likelihood</span>

            <span class="k">if</span> <span class="n">n_iter</span> <span class="o">&gt;</span> <span class="n">burn_in_iters</span> <span class="ow">and</span> <span class="n">m_change</span> <span class="o">&lt;</span> <span class="n">mean_change_tol</span><span class="p">:</span>
                <span class="c1"># DEBUG</span>
                <span class="c1"># print(&quot;converged iter: %d, ll: %.5f&quot; % (n_iter, likelihood))</span>
                <span class="k">break</span>

        <span class="c1"># update doc topic distribution</span>
        <span class="k">if</span> <span class="n">cal_doc_distr</span><span class="p">:</span>
            <span class="c1"># doc_topics, shape = (K,)</span>
            <span class="n">doc_topic_distr</span><span class="p">[</span><span class="n">idx_d</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">phi_row_sum</span><span class="p">,</span> <span class="n">zeta_d</span><span class="p">)</span>

        <span class="c1"># update sstats</span>
        <span class="k">if</span> <span class="n">cal_sstats</span><span class="p">:</span>
            <span class="n">suff_stats</span><span class="p">[</span><span class="s1">&#39;v_stick&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">zeta_d</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">suff_stats</span><span class="p">[</span><span class="s1">&#39;lambda&#39;</span><span class="p">][:,</span> <span class="n">ids</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">zeta_d</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">phi_all</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cal_likelihood</span><span class="p">:</span>
            <span class="n">doc_likelihood</span> <span class="o">+=</span> <span class="n">_local_likelihood_bound</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span>
                                                      <span class="n">elog_beta_d_weighted</span><span class="p">,</span>
                                                      <span class="n">elog_stick</span><span class="p">,</span>
                                                      <span class="n">gamma_d</span><span class="p">,</span>
                                                      <span class="n">elog_local_stick</span><span class="p">,</span>
                                                      <span class="n">log_phi_d</span><span class="p">,</span>
                                                      <span class="n">phi_d</span><span class="p">,</span>
                                                      <span class="n">log_zeta_d</span><span class="p">,</span>
                                                      <span class="n">zeta_d</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">doc_topic_distr</span><span class="p">,</span> <span class="n">suff_stats</span><span class="p">,</span> <span class="n">doc_likelihood</span>


<div class="viewcode-block" id="HierarchicalDirichletProcess"><a class="viewcode-back" href="../../template.html#bnp.online_hdp.HierarchicalDirichletProcess">[docs]</a><span class="k">class</span> <span class="nc">HierarchicalDirichletProcess</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Hierarchical Dirichlet Process with Stochastic Variational Inference</span>

<span class="sd">    HDP is the nonparametric version of LDA. The algorithm determines</span>
<span class="sd">    the number of topics based on data it fits instead of using a fixed</span>
<span class="sd">    number.</span>

<span class="sd">    Note: This implementation is described in Fig. 9 in [1]. A lot</span>
<span class="sd">          of greek letter are used as variable names. Check Fig. 8</span>
<span class="sd">          and Fig. 9 in [1] to know more about the alogrithm and each</span>
<span class="sd">          variable. Some of notation are different from original</span>
<span class="sd">          implementation in [3].</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_topic_truncate : int, optional (default=20)</span>
<span class="sd">        topics level truncation. In literature, it is `K`</span>

<span class="sd">    n_doc_truncate: int, optional (default=10)</span>
<span class="sd">        document level truncation. In literature, it is `T`</span>

<span class="sd">    omega: float, optional (default=1.0)</span>
<span class="sd">        topic level concentration</span>

<span class="sd">    alpha: float, optional (default=1.0)</span>
<span class="sd">        document level concentration</span>

<span class="sd">    eta: float, optional (default=1e-2)</span>
<span class="sd">        the topic Dirichlet prior</span>

<span class="sd">    learning_method : &#39;batch&#39; | &#39;online&#39;, default=&#39;online&#39;</span>
<span class="sd">        Method used to update latent variable. Only used in `fit` method.</span>

<span class="sd">    kappa : float, optional (default=0.5)</span>
<span class="sd">        This is forgetting rate in the online learning</span>
<span class="sd">        method. The value should be set between (0.5, 1.0] to guarantee</span>
<span class="sd">        asymptotic convergence. When the value is 0.0 and batch_size is</span>
<span class="sd">        ``n_samples``, the update method is same as batch learning.</span>

<span class="sd">    tau : float, optional (default=10.)</span>
<span class="sd">        A (positive) parameter that downweights early iterations in online</span>
<span class="sd">        learning.  It should be greater than 1.0.</span>

<span class="sd">    scale: float, optional (default=1.0)</span>
<span class="sd">        scale for learning rate.</span>

<span class="sd">    max_iter : int, optional (default=10)</span>
<span class="sd">        The maximum number of iterations.</span>

<span class="sd">    total_samples: int, optional (default=1e6))</span>
<span class="sd">        number of document. Only used in the `partial_fit` method.</span>

<span class="sd">    batch_size : int, optional (default=256)</span>
<span class="sd">        MiniBatch size. Number of documents to use in each EM iteration.</span>
<span class="sd">        Only used in online learning.</span>

<span class="sd">    evaluate_every : int, optional (default=0)</span>
<span class="sd">        How often to evaluate ELOB. Only used in `fit` method.</span>
<span class="sd">        set it to 0 or negative number to not evalute perplexity in</span>
<span class="sd">        training at all. Evaluating perplexity can help you check convergence</span>
<span class="sd">        in training process, but it will also increase total training time.</span>
<span class="sd">        Evaluating perplexity in every iteration might increase training time</span>
<span class="sd">        up to two-fold.</span>

<span class="sd">    perp_tol : float, optional (default=1e-1)</span>
<span class="sd">        Perplexity tolerance in batch learning. Only used when</span>
<span class="sd">        ``evaluate_every`` is greater than 0.</span>

<span class="sd">    mean_change_tol : float, optional (default=1e-3)</span>
<span class="sd">        Stopping tolerance for updating document topic distribution in E-step.</span>

<span class="sd">    max_doc_update_iter : int, optional (default=100)</span>
<span class="sd">        Max number of iterations for updating document topic distribution in</span>
<span class="sd">        the E-step.</span>

<span class="sd">    check_doc_likelihood : boolean, optional (default=False)</span>
<span class="sd">        Make sure doc log likelihood is increasing during e-step.</span>
<span class="sd">        Warnings will be printed if likelihood decreases. Also, this will</span>
<span class="sd">        significantly increase the training time.</span>

<span class="sd">    n_jobs : int, optional (default=1)</span>
<span class="sd">        The number of jobs to use in the E-step. If -1, all CPUs are used. For</span>
<span class="sd">        ``n_jobs`` below -1, (n_cpus + 1 + n_jobs) are used. Only used in</span>
<span class="sd">        batch learning now since it might not help when you do online learning</span>
<span class="sd">        with small batch size.</span>

<span class="sd">    verbose : int, optional (default=0)</span>
<span class="sd">        Verbosity level.</span>

<span class="sd">    random_state : int or RandomState instance or None, optional (default=None)</span>
<span class="sd">        Pseudo-random number generator seed control.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    lambda_: array, [n_topic_truncate, n_features]</span>
<span class="sd">        Golbal Variational parameter for topic word distribution (`beta`)</span>
<span class="sd">        q(beta) ~ Direchlet(lambda)</span>

<span class="sd">    v_stick_: array, [2, n_topic_truncate-1]</span>
<span class="sd">        Golbal Variational parameter for topic stick length (`v`)</span>
<span class="sd">        q(v_k) ~ Beta(a_[0, k], a_1[1, k])</span>

<span class="sd">    n_mini_batch_iter_ : int</span>
<span class="sd">        Number of iterations of the mini-batch EM step.</span>

<span class="sd">    n_iter_ : int</span>
<span class="sd">        Number of passes over the dataset.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] &quot;Stochastic Variational Inference&quot;, Matthew D. Hoffman, David M. Blei,</span>
<span class="sd">        Chong Wang, John Paisley, 2013</span>

<span class="sd">    [2] &quot;Online Variational Inference for the Hierarchical Dirichlet Process&quot;,</span>
<span class="sd">        Chong Wang, John Paisley, David M. Blei, 2011</span>

<span class="sd">    [3] Chong Wang&#39;s online-hdp code. Link:</span>
<span class="sd">        https://github.com/blei-lab/online-hdp</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_topic_truncate</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_doc_truncate</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">omega</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">learning_method</span><span class="o">=</span><span class="s1">&#39;online&#39;</span><span class="p">,</span> <span class="n">kappa</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                 <span class="n">tau</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">total_samples</span><span class="o">=</span><span class="mf">1e6</span><span class="p">,</span>
                 <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">evaluate_every</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">perp_tol</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span>
                 <span class="n">mean_change_tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">max_doc_update_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                 <span class="n">check_doc_likelihood</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">burn_in_iters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_topic_truncate</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_topic_truncate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_doc_truncate</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_doc_truncate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">omega</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">omega</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">eta</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_method</span> <span class="o">=</span> <span class="n">learning_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kappa</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">kappa</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">max_iter</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">total_samples</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_every</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">evaluate_every</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">perp_tol</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">perp_tol</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_change_tol</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">mean_change_tol</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_doc_update_iter</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">max_doc_update_iter</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_doc_likelihood</span> <span class="o">=</span> <span class="n">check_doc_likelihood</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_jobs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">burn_in_iters</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">burn_in_iters</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">verbose</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>

    <span class="k">def</span> <span class="nf">_check_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Check model parameters.&quot;&quot;&quot;</span>
        <span class="n">pos_int_params</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s1">&#39;n_topic_truncate&#39;</span><span class="p">,</span>
            <span class="s1">&#39;n_doc_truncate&#39;</span><span class="p">,</span>
            <span class="s1">&#39;total_samples&#39;</span><span class="p">,</span>
            <span class="s1">&#39;max_iter&#39;</span>
        <span class="p">]</span>

        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">pos_int_params</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">val</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid &#39;</span><span class="si">%s</span><span class="s2">&#39; parameter: </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span> <span class="s2">&quot;online&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid &#39;learning_method&#39; parameter: </span><span class="si">%r</span><span class="s2">&quot;</span>
                             <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_method</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_non_neg_array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">whom</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;check X format</span>
<span class="sd">        check X format and make sure no negative value in X.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X :  array-like or sparse matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s1">&#39;csr&#39;</span><span class="p">)</span>
        <span class="n">check_non_negative</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">whom</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span>

    <span class="k">def</span> <span class="nf">_check_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">whom</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Check inference conditions</span>

<span class="sd">        The function will check model is fitted and input matrix</span>
<span class="sd">        has correct shape &amp; value</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;lambda_&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">NotFittedError</span><span class="p">(</span><span class="s2">&quot;no &#39;lambda_&#39; attribute in model.&quot;</span>
                                 <span class="s2">&quot; Please fit model first.&quot;</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_non_neg_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">whom</span><span class="p">)</span>

        <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">n_features</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The provided data has </span><span class="si">%d</span><span class="s2"> dimensions while &quot;</span>
                <span class="s2">&quot;the model was trained with feature size </span><span class="si">%d</span><span class="s2">.&quot;</span> <span class="o">%</span>
                <span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">X</span>

    <span class="k">def</span> <span class="nf">_init_global_latent_vars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_docs</span><span class="p">,</span> <span class="n">n_features</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize latent variables.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">random_state_</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># initialize global variational variables</span>
        <span class="c1"># follow reference [3]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_state_</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span>
            <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_topic_truncate</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span> <span class="o">*</span> \
            <span class="p">(</span><span class="n">n_docs</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_topic_truncate</span> <span class="o">*</span> <span class="n">n_features</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">elog_beta_</span> <span class="o">=</span> <span class="n">log_dirichlet_expectation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">)</span>

        <span class="c1"># Beta distribution for stick break process</span>
        <span class="c1"># Note: use Beta(1, omega) as initial stick based on [1]</span>
        <span class="c1"># self.v_stick_ = np.array(</span>
        <span class="c1">#    [np.ones(self.n_topic_truncate-1),</span>
        <span class="c1">#     np.repeat(self.omega, self.n_topic_truncate-1)])</span>
        <span class="c1"># uniform stick</span>
        <span class="c1"># Note: use uniform distribution here based on [3]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_stick_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_topic_truncate</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                                  <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_topic_truncate</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">elog_v_stick_</span> <span class="o">=</span> <span class="n">log_stick_expectation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_stick_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sstats_v_stick_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_topic_truncate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_init_min_batch_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_mini_batch_iter_</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">_get_step_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">rhot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_mini_batch_iter_</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">kappa</span><span class="p">)</span>
        <span class="n">rhot</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">rhot</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_mini_batch_iter_</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">rhot</span>

    <span class="k">def</span> <span class="nf">_e_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">cal_sstats</span><span class="p">,</span> <span class="n">cal_doc_distr</span><span class="p">,</span>
                <span class="n">cal_likelihood</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="k">if</span> <span class="n">parallel</span><span class="p">:</span>
            <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">parallel</span><span class="o">.</span><span class="n">n_jobs</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span><span class="n">delayed</span><span class="p">(</span>
                <span class="n">_update_var_local_params</span><span class="p">)(</span><span class="n">X</span><span class="p">[</span><span class="n">idx_slice</span><span class="p">,</span> <span class="p">:],</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">elog_beta_</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">elog_v_stick_</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">n_doc_truncate</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">max_doc_update_iter</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">mean_change_tol</span><span class="p">,</span>
                                          <span class="n">cal_sstats</span><span class="p">,</span>
                                          <span class="n">cal_doc_distr</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">burn_in_iters</span><span class="p">,</span>
                                          <span class="bp">self</span><span class="o">.</span><span class="n">check_doc_likelihood</span><span class="p">,</span>
                                          <span class="n">cal_likelihood</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">idx_slice</span> <span class="ow">in</span> <span class="n">gen_even_slices</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n_jobs</span><span class="p">))</span>
            <span class="n">doc_topics</span><span class="p">,</span> <span class="n">sstats_list</span><span class="p">,</span> <span class="n">ll_list</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">results</span><span class="p">)</span>

            <span class="n">doc_topic_distr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">doc_topics</span><span class="p">)</span> <span class="k">if</span> <span class="n">cal_doc_distr</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="n">doc_likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ll_list</span><span class="p">)</span> <span class="k">if</span> <span class="n">cal_likelihood</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="n">sstats</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">cal_sstats</span><span class="p">:</span>
                <span class="n">lambda_sstats</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">v_stick_sstats</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_topic_truncate</span><span class="p">,</span> <span class="p">))</span>
                <span class="k">for</span> <span class="n">sstats</span> <span class="ow">in</span> <span class="n">sstats_list</span><span class="p">:</span>
                    <span class="n">lambda_sstats</span> <span class="o">+=</span> <span class="n">sstats</span><span class="p">[</span><span class="s1">&#39;lambda&#39;</span><span class="p">]</span>
                    <span class="n">v_stick_sstats</span> <span class="o">+=</span> <span class="n">sstats</span><span class="p">[</span><span class="s1">&#39;v_stick&#39;</span><span class="p">]</span>
                <span class="n">sstats</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s1">&#39;lambda&#39;</span><span class="p">:</span> <span class="n">lambda_sstats</span><span class="p">,</span>
                    <span class="s1">&#39;v_stick&#39;</span><span class="p">:</span> <span class="n">v_stick_sstats</span><span class="p">,</span>
                <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">doc_topic_distr</span><span class="p">,</span> <span class="n">sstats</span><span class="p">,</span> <span class="n">doc_likelihood</span> <span class="o">=</span> \
                <span class="n">_update_var_local_params</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">elog_beta_</span><span class="p">,</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">elog_v_stick_</span><span class="p">,</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">n_doc_truncate</span><span class="p">,</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">max_doc_update_iter</span><span class="p">,</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">mean_change_tol</span><span class="p">,</span>
                                         <span class="n">cal_sstats</span><span class="p">,</span>
                                         <span class="n">cal_doc_distr</span><span class="p">,</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">burn_in_iters</span><span class="p">,</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">check_doc_likelihood</span><span class="p">,</span>
                                         <span class="n">cal_likelihood</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">doc_topic_distr</span><span class="p">,</span> <span class="n">sstats</span><span class="p">,</span> <span class="n">doc_likelihood</span><span class="p">)</span>

    <span class="c1"># def _optimal_ordering(self):</span>
    <span class="c1">#    &quot;&quot;&quot;ordering the topics</span>
    <span class="c1">#</span>
    <span class="c1">#    From ref [3]</span>
    <span class="c1">#    &quot;&quot;&quot;</span>
    <span class="c1">#    labda_sum = np.sum(self.lambda_, axis=1)</span>
    <span class="c1">#    idx = [i for i in reversed(np.argsort(labda_sum))]</span>
    <span class="c1">#    self.lambda_ = self.lambda_[idx, :]</span>
    <span class="c1">#    self.sstats_v_stick_ = self.sstats_v_stick_[idx]</span>

    <span class="k">def</span> <span class="nf">_m_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sstats</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">online_update</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">n_topics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_topic_truncate</span>

        <span class="k">if</span> <span class="n">online_update</span><span class="p">:</span>
            <span class="n">doc_ratio</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_samples</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_samples</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_step_size</span><span class="p">()</span>
            <span class="c1"># update lambda</span>
            <span class="n">sstats_lambda</span> <span class="o">=</span> <span class="n">sstats</span><span class="p">[</span><span class="s1">&#39;lambda&#39;</span><span class="p">]</span>
            <span class="n">sstats_lambda</span> <span class="o">*=</span> <span class="n">doc_ratio</span>
            <span class="n">sstats_lambda</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta</span>
            <span class="n">sstats_lambda</span> <span class="o">*=</span> <span class="n">weight</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span> <span class="o">*=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">weight</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span> <span class="o">+=</span> <span class="n">sstats_lambda</span>

            <span class="c1"># update v_stick (based on [3])</span>
            <span class="n">sstats_v_stick</span> <span class="o">=</span> <span class="n">sstats</span><span class="p">[</span><span class="s1">&#39;v_stick&#39;</span><span class="p">]</span>
            <span class="n">sstats_v_stick</span> <span class="o">*=</span> <span class="p">(</span><span class="n">weight</span> <span class="o">*</span> <span class="n">doc_ratio</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sstats_v_stick_</span> <span class="o">*=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">weight</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sstats_v_stick_</span> <span class="o">+=</span> <span class="n">sstats_v_stick</span>

            <span class="c1"># self._optimal_ordering()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">v_stick_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sstats_v_stick_</span><span class="p">[:</span><span class="n">n_topics</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1.</span>
            <span class="c1"># flip -&gt; cumsum -&gt; flip back</span>
            <span class="n">sum_from_end</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flipud</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">flipud</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sstats_v_stick_</span><span class="p">[</span><span class="mi">1</span><span class="p">:])))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v_stick_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">omega</span> <span class="o">+</span> <span class="n">sum_from_end</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># batch update</span>
            <span class="c1"># lambda</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">+</span> <span class="n">sstats</span><span class="p">[</span><span class="s1">&#39;lambda&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sstats_v_stick_</span> <span class="o">=</span> <span class="n">sstats</span><span class="p">[</span><span class="s1">&#39;v_stick&#39;</span><span class="p">]</span>
            <span class="c1"># self._optimal_ordering()</span>

            <span class="c1"># stick</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v_stick_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">+</span> <span class="n">sstats</span><span class="p">[</span><span class="s1">&#39;v_stick&#39;</span><span class="p">][:</span><span class="n">n_topics</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="c1"># flip -&gt; cumsum -&gt; flip back</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v_stick_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">omega</span> <span class="o">+</span> \
                <span class="n">np</span><span class="o">.</span><span class="n">flipud</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">flipud</span><span class="p">(</span><span class="n">sstats</span><span class="p">[</span><span class="s1">&#39;v_stick&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">:])))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">elog_beta_</span> <span class="o">=</span> <span class="n">log_dirichlet_expectation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">elog_v_stick_</span> <span class="o">=</span> <span class="n">log_stick_expectation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_stick_</span><span class="p">)</span>

<div class="viewcode-block" id="HierarchicalDirichletProcess.partial_fit"><a class="viewcode-back" href="../../template.html#bnp.online_hdp.HierarchicalDirichletProcess.partial_fit">[docs]</a>    <span class="k">def</span> <span class="nf">partial_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Online VB with Mini-Batch update.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like or sparse matrix, shape=(n_samples, n_features)</span>
<span class="sd">            Document word matrix.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_non_neg_array</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="s2">&quot;HierarchicalDirichletProcess.partial_fit&quot;</span><span class="p">)</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>

        <span class="c1"># reset global if no &#39;n_mini_batch_iter_&#39; param</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;n_mini_batch_iter_&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_min_batch_parameters</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_global_latent_vars</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_features</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The provided data has </span><span class="si">%d</span><span class="s2"> dimensions while &quot;</span>
                <span class="s2">&quot;the model was trained with feature size </span><span class="si">%d</span><span class="s2">.&quot;</span> <span class="o">%</span>
                <span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

        <span class="k">for</span> <span class="n">idx_slice</span> <span class="ow">in</span> <span class="n">gen_batches</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">X_slice</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idx_slice</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">sstats</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e_step</span><span class="p">(</span><span class="n">X_slice</span><span class="p">,</span>
                                        <span class="n">cal_sstats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                        <span class="n">cal_doc_distr</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                        <span class="n">cal_likelihood</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                        <span class="n">parallel</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_m_step</span><span class="p">(</span><span class="n">sstats</span><span class="p">,</span>
                         <span class="n">n_samples</span><span class="o">=</span><span class="n">X_slice</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                         <span class="n">online_update</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="HierarchicalDirichletProcess.fit"><a class="viewcode-back" href="../../template.html#bnp.online_hdp.HierarchicalDirichletProcess.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Learn model for the data X</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like or sparse matrix, shape=(n_samples, n_features)</span>
<span class="sd">            Document word matrix.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_params</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_non_neg_array</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="s2">&quot;HierarchicalDirichletProcess.fit&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_global_latent_vars</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">_get_n_jobs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">)</span>
        <span class="n">verbose</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">evaluate_every</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_every</span>
        <span class="k">with</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span> <span class="k">as</span> <span class="n">parallel</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">):</span>
                <span class="c1"># batch update</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">sstats</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                            <span class="n">cal_sstats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                            <span class="n">cal_doc_distr</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                            <span class="n">cal_likelihood</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                            <span class="n">parallel</span><span class="o">=</span><span class="n">parallel</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_m_step</span><span class="p">(</span><span class="n">sstats</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">online_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

                <span class="c1"># check perplexity</span>
                <span class="k">if</span> <span class="n">evaluate_every</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">evaluate_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">bound</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;iteration: </span><span class="si">%d</span><span class="s1">, ELOB: </span><span class="si">%.4f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bound</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="HierarchicalDirichletProcess.transform"><a class="viewcode-back" href="../../template.html#bnp.online_hdp.HierarchicalDirichletProcess.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Transform data X according to the fitted model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like or sparse matrix, shape=(n_samples, n_features)</span>
<span class="sd">            Document word matrix.</span>


<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        doc_topic_distr : shape=(n_samples, n_topics)</span>
<span class="sd">            Unnormalized document topic distribution for X.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inference</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s2">&quot;HierarchicalDirichletProcess.transform&quot;</span><span class="p">)</span>

        <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">_get_n_jobs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">)</span>
        <span class="n">verbose</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span> <span class="k">as</span> <span class="n">parallel</span><span class="p">:</span>
            <span class="n">doc_topic_distr</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                                 <span class="n">cal_sstats</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                 <span class="n">cal_doc_distr</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                 <span class="n">cal_likelihood</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                 <span class="n">parallel</span><span class="o">=</span><span class="n">parallel</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">doc_topic_distr</span></div>

<div class="viewcode-block" id="HierarchicalDirichletProcess.topic_distribution"><a class="viewcode-back" href="../../template.html#bnp.online_hdp.HierarchicalDirichletProcess.topic_distribution">[docs]</a>    <span class="k">def</span> <span class="nf">topic_distribution</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Topic distribution from stick-break process</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        topic_distr : shape=(n_topics,)</span>
<span class="sd">            topic distribution from stick-breaking process. (sum to 1.)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;lambda_&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">NotFittedError</span><span class="p">(</span><span class="s2">&quot;no &#39;lambda_&#39; attribute in model.&quot;</span>
                                 <span class="s2">&quot; Please fit model first.&quot;</span><span class="p">)</span>

        <span class="n">topic_distr</span> <span class="o">=</span> <span class="n">stick_expectation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_stick_</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">topic_distr</span></div>

    <span class="k">def</span> <span class="nf">_approximate_bound</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calculate approximate log-likelihood for the model</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like or sparse matrix, shape=(n_samples, n_features)</span>
<span class="sd">            Document word matrix.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        likelihood : float</span>
<span class="sd">            approximate log-likelihood for variational parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">likelihood</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="c1"># calculate doc likelihood</span>
        <span class="n">n_jobs</span> <span class="o">=</span> <span class="n">_get_n_jobs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">)</span>
        <span class="n">verbose</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span> <span class="k">as</span> <span class="n">parallel</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">doc_likelihood</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e_step</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                                <span class="n">cal_sstats</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                <span class="n">cal_doc_distr</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                <span class="n">cal_likelihood</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                <span class="n">parallel</span><span class="o">=</span><span class="n">parallel</span><span class="p">)</span>
        <span class="n">likelihood</span> <span class="o">+=</span> <span class="n">doc_likelihood</span>

        <span class="c1"># E[log(p(beta|eta) - log(q(beta|lambda))]</span>
        <span class="c1"># `beta` is Dirichlet distribution</span>
        <span class="n">lambda_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span>
        <span class="n">elog_beta_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">elog_beta_</span>
        <span class="n">n_features</span> <span class="o">=</span> <span class="n">lambda_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">likelihood</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">-</span> <span class="n">lambda_</span><span class="p">)</span> <span class="o">*</span> <span class="n">elog_beta_</span><span class="p">)</span>
        <span class="n">likelihood</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gammaln</span><span class="p">(</span><span class="n">lambda_</span><span class="p">)</span> <span class="o">-</span> <span class="n">gammaln</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">))</span>
        <span class="n">likelihood</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gammaln</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">*</span> <span class="n">n_features</span><span class="p">)</span> <span class="o">-</span>
                             <span class="n">gammaln</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lambda_</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>

        <span class="c1"># E[log(p(v_k|omega)) - log(q(v_k|a_k))]</span>
        <span class="c1"># `v_k` is Beta distribution</span>
        <span class="n">v_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_stick_</span>
        <span class="n">likelihood</span> <span class="o">+=</span> <span class="p">(</span><span class="n">v_k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">omega</span><span class="p">))</span>
        <span class="n">v_k_col_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">v_k</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">dig_sum</span> <span class="o">=</span> <span class="n">psi</span><span class="p">(</span><span class="n">v_k_col_sum</span><span class="p">)</span>
        <span class="n">likelihood</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">omega</span><span class="p">])[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">-</span> <span class="n">v_k</span><span class="p">)</span> <span class="o">*</span>
            <span class="p">(</span><span class="n">psi</span><span class="p">(</span><span class="n">v_k</span><span class="p">)</span> <span class="o">-</span> <span class="n">dig_sum</span><span class="p">))</span>
        <span class="n">likelihood</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gammaln</span><span class="p">(</span><span class="n">v_k</span><span class="p">))</span>
        <span class="n">likelihood</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gammaln</span><span class="p">(</span><span class="n">v_k_col_sum</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">likelihood</span>

<div class="viewcode-block" id="HierarchicalDirichletProcess.score"><a class="viewcode-back" href="../../template.html#bnp.online_hdp.HierarchicalDirichletProcess.score">[docs]</a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calculate approximate log-likelihood as score.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like or sparse matrix, shape=(n_samples, n_features)</span>
<span class="sd">            Document word matrix.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            Use approximate bound as score.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inference</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s2">&quot;HierarchicalDirichletProcess.score&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_approximate_bound</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Vighnesh Birodkar.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.1.0',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>